#!/usr/bin/env python3
"""
å°è¯´é˜…è¯»æ•°æ®åˆ†æå·¥å…·
ç”¨äºåˆ†æGoogle Analyticså¯¼å‡ºçš„æ•°æ®ï¼ŒæŒ‰å°è¯´å’Œæ—¥æœŸç»Ÿè®¡é˜…è¯»é‡
"""

import pandas as pd
import json
from datetime import datetime
from pathlib import Path
import re

class NovelAnalytics:
    def __init__(self):
        self.data = None
        
    def load_ga_export(self, csv_file_path):
        """
        åŠ è½½Google Analyticså¯¼å‡ºçš„CSVæ–‡ä»¶
        éœ€è¦åŒ…å«ä»¥ä¸‹åˆ—ï¼šæ—¥æœŸã€é¡µé¢è·¯å¾„ã€é¡µé¢æµè§ˆé‡
        """
        try:
            self.data = pd.read_csv(csv_file_path)
            print(f"æˆåŠŸåŠ è½½æ•°æ®ï¼š{len(self.data)} æ¡è®°å½•")
            return True
        except Exception as e:
            print(f"åŠ è½½æ•°æ®å¤±è´¥ï¼š{e}")
            return False
    
    def extract_novel_info(self, page_path):
        """
        ä»é¡µé¢è·¯å¾„ä¸­æå–å°è¯´ä¿¡æ¯
        """
        # åŒ¹é…æ¨¡å¼ï¼š/novels/novel-name/chapter-X.html
        pattern = r'/novels/([^/]+)/chapter-(\d+)\.html'
        match = re.search(pattern, page_path)
        
        if match:
            novel_slug = match.group(1)
            chapter_num = int(match.group(2))
            
            # å°†URL slugè½¬æ¢ä¸ºå¯è¯»çš„å°è¯´æ ‡é¢˜
            novel_title = novel_slug.replace('-', ' ').title()
            
            return {
                'novel_title': novel_title,
                'novel_slug': novel_slug,
                'chapter_number': chapter_num
            }
        return None
    
    def analyze_by_novel_and_date(self):
        """
        æŒ‰å°è¯´å’Œæ—¥æœŸåˆ†æé˜…è¯»é‡
        """
        if self.data is None:
            print("è¯·å…ˆåŠ è½½æ•°æ®")
            return None
        
        # å‡è®¾CSVåˆ—åï¼ˆæ ¹æ®å®é™…GAå¯¼å‡ºè°ƒæ•´ï¼‰
        date_col = 'Date'  # æˆ– 'æ—¥æœŸ'
        path_col = 'Page'  # æˆ– 'é¡µé¢è·¯å¾„'
        views_col = 'Pageviews'  # æˆ– 'é¡µé¢æµè§ˆé‡'
        
        results = []
        
        for index, row in self.data.iterrows():
            novel_info = self.extract_novel_info(row[path_col])
            
            if novel_info:
                results.append({
                    'date': row[date_col],
                    'novel_title': novel_info['novel_title'],
                    'novel_slug': novel_info['novel_slug'],
                    'chapter_views': row[views_col],
                    'chapter_number': novel_info['chapter_number']
                })
        
        # è½¬æ¢ä¸ºDataFrameå¹¶æŒ‰æ—¥æœŸã€å°è¯´åˆ†ç»„æ±‡æ€»
        df = pd.DataFrame(results)
        
        if not df.empty:
            # æŒ‰æ—¥æœŸå’Œå°è¯´åˆ†ç»„ï¼Œæ±‡æ€»ç« èŠ‚é˜…è¯»é‡
            summary = df.groupby(['date', 'novel_title']).agg({
                'chapter_views': 'sum',
                'chapter_number': 'count'  # è¢«é˜…è¯»çš„ç« èŠ‚æ•°é‡
            }).reset_index()
            
            summary.columns = ['æ—¥æœŸ', 'å°è¯´æ ‡é¢˜', 'æ€»é˜…è¯»é‡', 'è¢«é˜…è¯»ç« èŠ‚æ•°']
            
            return summary
        
        return None
    
    def generate_daily_report(self, output_file='novel_reading_report.json'):
        """
        ç”Ÿæˆæ¯æ—¥å°è¯´é˜…è¯»æŠ¥å‘Š
        """
        summary = self.analyze_by_novel_and_date()
        
        if summary is not None:
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ä¾¿äºæŸ¥çœ‹
            report = {}
            
            for index, row in summary.iterrows():
                date = row['æ—¥æœŸ']
                novel = row['å°è¯´æ ‡é¢˜']
                total_views = row['æ€»é˜…è¯»é‡']
                chapters_read = row['è¢«é˜…è¯»ç« èŠ‚æ•°']
                
                if date not in report:
                    report[date] = {}
                
                report[date][novel] = {
                    'æ€»é˜…è¯»é‡': int(total_views),
                    'è¢«é˜…è¯»ç« èŠ‚æ•°': int(chapters_read)
                }
            
            # ä¿å­˜æŠ¥å‘Š
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            print(f"æŠ¥å‘Šå·²ç”Ÿæˆï¼š{output_file}")
            
            # æ˜¾ç¤ºç®€è¦ç»Ÿè®¡
            print("\n=== å°è¯´é˜…è¯»ç»Ÿè®¡æ‘˜è¦ ===")
            for date, novels in report.items():
                print(f"\nğŸ“… {date}")
                for novel, stats in novels.items():
                    print(f"  ğŸ“– {novel}: {stats['æ€»é˜…è¯»é‡']} æ¬¡é˜…è¯»ï¼Œ{stats['è¢«é˜…è¯»ç« èŠ‚æ•°']} ä¸ªç« èŠ‚")
            
            return report
        
        return None

def main():
    """
    ä½¿ç”¨ç¤ºä¾‹
    """
    print("ğŸ“Š å°è¯´é˜…è¯»æ•°æ®åˆ†æå·¥å…·")
    print("\nä½¿ç”¨æ­¥éª¤ï¼š")
    print("1. ç™»å½• Google Analytics (analytics.google.com)")
    print("2. é€‰æ‹©ä½ çš„ç½‘ç«™å±æ€§")
    print("3. è¿›å…¥ æŠ¥å‘Š â†’ å‚ä¸åº¦ â†’ é¡µé¢å’Œå±å¹•")
    print("4. è®¾ç½®æ—¥æœŸèŒƒå›´")
    print("5. æ·»åŠ ç­›é€‰å™¨ï¼šé¡µé¢è·¯å¾„åŒ…å« '/novels/'")
    print("6. å¯¼å‡ºä¸ºCSVæ–‡ä»¶")
    print("7. è¿è¡Œæ­¤è„šæœ¬åˆ†ææ•°æ®")
    print("\n" + "="*50)
    
    # ç¤ºä¾‹ç”¨æ³•ï¼ˆéœ€è¦å®é™…çš„CSVæ–‡ä»¶ï¼‰
    analyzer = NovelAnalytics()
    
    # æ›¿æ¢ä¸ºå®é™…çš„CSVæ–‡ä»¶è·¯å¾„
    csv_file = "ga_export.csv"
    
    if Path(csv_file).exists():
        if analyzer.load_ga_export(csv_file):
            analyzer.generate_daily_report()
    else:
        print(f"\nè¯·å°†Google Analyticså¯¼å‡ºçš„CSVæ–‡ä»¶ä¿å­˜ä¸ºï¼š{csv_file}")
        print("æˆ–ä¿®æ”¹è„šæœ¬ä¸­çš„æ–‡ä»¶è·¯å¾„")

if __name__ == "__main__":
    main()